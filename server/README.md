# ðŸ¤–+ðŸ‘± SocialAGI Server

âš¡ SocialAGI Server is a simple server for hosting digital souls âš¡

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg) ![Twitter](https://img.shields.io/twitter/url/https/twitter.com/socialagi.svg?style=social&label=Follow%20%40socialagi)](https://twitter.com/socialagi) [![](https://dcbadge.vercel.app/api/server/Dx3FYccm?compact=true&style=flat)](https://discord.gg/Dx3FYccm)

More specifically, the SocialAGI server is an Express.js based application that interfaces with `socialagi` powered chatbots to listen to messages and thoughts. The server uses Server-Sent Events (SSE) to provide real-time updates to clients.

## Getting started

Install the package's dependencies

```$ npm install```

Set the environment variables

`$ export SOCIALAGI_PORT=...`: The port on which the server should run (default: 5001).

`$ export OPENAI_API_KEY=...`: Your OpenAI API key for authentication with the OpenAI api.

Run the server

```$ npm run start```

While developing, the easiest way to talk to the server is through the [`socialagi-devtools` NPM package](https://www.npmjs.com/package/socialagi-devtools).

Simply run
```bash
npm i -g socialagi-devtools
socialagi-devtools 
```

By default, the server hosts Samantha from [Meet Samantha](http://meetsamantha.ai).

## Server API Endpoints

`/listenMessages`: GET request for receiving real-time messages from the SocialAGI server. This endpoint sets up an event stream to send messages as they are received from Samantha.

`/listenThoughts`: GET request for receiving real-time thoughts from the SocialAGI server. This endpoint sets up an event stream to send thoughts as they are generated by Samantha.

`/tell`: POST request for sending a message to the SocialAGI server. The request body should contain a JSON object with the message property.
